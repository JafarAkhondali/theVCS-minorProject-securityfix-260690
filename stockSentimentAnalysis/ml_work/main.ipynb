{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.7.10 64-bit ('conda': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "#from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandasql as psql\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/stockmarket-sentiment-dataset/stock_data.csv\")\n",
    "df.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user I'd be afraid to short AMZN - they are lo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MNTA Over 12.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OI  Over 21.37</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " 1    3685\n",
       "-1    2106\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "document = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    document.append((re.sub(r\"[^a-zA-Z]\",\" \",row[\"Text\"]), row[\"Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Kickers on my watchlist XIDE TIT SOQ PNK CPW BPZ AJ  trade method   or method    see prev posts',\n",
       "  1),\n",
       " ('user  AAP MOVIE      return for the FEA GEED indicator just    trades for the year   AWESOME   ',\n",
       "  1)]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "document[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(['Kickers',\n",
       "   'on',\n",
       "   'my',\n",
       "   'watchlist',\n",
       "   'XIDE',\n",
       "   'TIT',\n",
       "   'SOQ',\n",
       "   'PNK',\n",
       "   'CPW',\n",
       "   'BPZ',\n",
       "   'AJ',\n",
       "   'trade',\n",
       "   'method',\n",
       "   'or',\n",
       "   'method',\n",
       "   'see',\n",
       "   'prev',\n",
       "   'posts'],\n",
       "  1)]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "parsed_document = []\n",
    "\n",
    "for text,sentiment in document:\n",
    "    parsed_document.append((word_tokenize(text), sentiment))\n",
    "\n",
    "parsed_document[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = parsed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(['Kickers',\n",
       "   'watchlist',\n",
       "   'XIDE',\n",
       "   'TIT',\n",
       "   'SOQ',\n",
       "   'PNK',\n",
       "   'CPW',\n",
       "   'BPZ',\n",
       "   'AJ',\n",
       "   'trade',\n",
       "   'method',\n",
       "   'method',\n",
       "   'see',\n",
       "   'prev',\n",
       "   'posts'],\n",
       "  1)]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words(\"english\")\n",
    "\n",
    "parsed_document = []\n",
    "\n",
    "for words, sentiment in document:\n",
    "    parsed_document.append(([word for word in words if word not in stopWords], sentiment))\n",
    "parsed_document[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = parsed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(['kickers',\n",
       "   'watchlist',\n",
       "   'xide',\n",
       "   'tit',\n",
       "   'soq',\n",
       "   'pnk',\n",
       "   'cpw',\n",
       "   'bpz',\n",
       "   'aj',\n",
       "   'trade',\n",
       "   'method',\n",
       "   'method',\n",
       "   'see',\n",
       "   'prev',\n",
       "   'posts'],\n",
       "  1)]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "parsed_document = []\n",
    "\n",
    "for words, sentiment in document:\n",
    "    parsed_document.append(([word.lower() for word in words if word], sentiment))\n",
    "parsed_document[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = parsed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(['kicker',\n",
       "   'watchlist',\n",
       "   'xide',\n",
       "   'tit',\n",
       "   'soq',\n",
       "   'pnk',\n",
       "   'cpw',\n",
       "   'bpz',\n",
       "   'aj',\n",
       "   'trade',\n",
       "   'method',\n",
       "   'method',\n",
       "   'see',\n",
       "   'prev',\n",
       "   'post'],\n",
       "  1)]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "parsed_document = []\n",
    "\n",
    "for words, sentiment in document:\n",
    "    parsed_document.append(([ps.stem(word) for word in words if word], sentiment))\n",
    "parsed_document[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = parsed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['kicker',\n",
       " 'watchlist',\n",
       " 'xide',\n",
       " 'tit',\n",
       " 'soq',\n",
       " 'pnk',\n",
       " 'cpw',\n",
       " 'bpz',\n",
       " 'aj',\n",
       " 'trade',\n",
       " 'method',\n",
       " 'method',\n",
       " 'see',\n",
       " 'prev',\n",
       " 'post']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "for words, sentiment in document:\n",
    "    for word in words:\n",
    "        all_words.append(word)\n",
    "\n",
    "all_words[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('aap', 929),\n",
       " ('co', 711),\n",
       " ('http', 696),\n",
       " ('user', 648),\n",
       " ('i', 559),\n",
       " ('short', 522),\n",
       " ('day', 385),\n",
       " ('stock', 372),\n",
       " ('today', 347),\n",
       " ('like', 334),\n",
       " ('look', 327),\n",
       " ('volum', 308),\n",
       " ('market', 291),\n",
       " ('buy', 290),\n",
       " ('long', 282)]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "freDistWords = FreqDist(all_words)\n",
    "freDistWords.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7273"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "len(freDistWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aap\nco\nhttp\nuser\ni\nshort\nday\nstock\ntoday\nlike\nlook\nvolum\nmarket\nbuy\nlong\n"
     ]
    }
   ],
   "source": [
    "for i,j in freDistWords.most_common(15):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmt = 5000\n",
    "wordFeatures = []\n",
    "\n",
    "for i,j in freDistWords.most_common(lmt):\n",
    "    wordFeatures.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['aap',\n",
       " 'co',\n",
       " 'http',\n",
       " 'user',\n",
       " 'i',\n",
       " 'short',\n",
       " 'day',\n",
       " 'stock',\n",
       " 'today',\n",
       " 'like',\n",
       " 'look',\n",
       " 'volum',\n",
       " 'market',\n",
       " 'buy',\n",
       " 'long']"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "wordFeatures[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(document):\n",
    "    document = set(document)\n",
    "    features = {}\n",
    "\n",
    "    for word in wordFeatures:\n",
    "        features[word] = (word in document)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = [(getFeatures(document),sentiment) for document, sentiment in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5791"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "len(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = feature_set[:4500], feature_set[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9868319132455461"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "modelLogisticRegression = SklearnClassifier(LogisticRegression())\n",
    "modelLogisticRegression.train(test_set)\n",
    "nltk.classify.accuracy(modelLogisticRegression, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "modelDecisionTreeClassifier = SklearnClassifier(DecisionTreeClassifier())\n",
    "modelDecisionTreeClassifier.train(test_set)\n",
    "nltk.classify.accuracy(modelDecisionTreeClassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "modelRandomForestClassifier = SklearnClassifier(RandomForestClassifier())\n",
    "modelRandomForestClassifier.train(test_set)\n",
    "nltk.classify.accuracy(modelRandomForestClassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9821843532145623"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "modelSVC = SklearnClassifier(svm.SVC())\n",
    "modelSVC.train(test_set)\n",
    "nltk.classify.accuracy(modelSVC, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.919442292796282"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "modelMultinomialNB = SklearnClassifier(MultinomialNB())\n",
    "modelMultinomialNB.train(test_set)\n",
    "nltk.classify.accuracy(modelMultinomialNB, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9085979860573199"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "modelBernoulliNB = SklearnClassifier(BernoulliNB())\n",
    "modelBernoulliNB.train(test_set)\n",
    "nltk.classify.accuracy(modelBernoulliNB, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ClassifierI\n",
    "from scipy.stats import mode\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, classifiers):\n",
    "        self.classifiers = classifiers\n",
    "\n",
    "    def classify(self,features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self.classifiers:\n",
    "            votes.append(c.classify(features))\n",
    "\n",
    "        return mode(votes)[0]\n",
    "\n",
    "    def confidence(self,features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self.classifiers:\n",
    "            votes.append(c.classify(features))\n",
    "\n",
    "        cnt = votes.count(mode(votes)[0])\n",
    "        return (cnt/len(votes))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "voteClassifier = VoteClassifier([modelRandomForestClassifier, modelDecisionTreeClassifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "nltk.classify.accuracy(voteClassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "joblib.dump(voteClassifier, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"allWords.json\", \"w\") as f:\n",
    "    json.dump({\"allWords\": wordFeatures}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}